from __future__ import annotations

import logging
from collections.abc import Mapping
from dataclasses import dataclass

from src.domain.models import ArtifactKind, LLMPlan, PlanStep, PlanStepType, is_safe_job_rel_path
from src.infra.exceptions import (
    DoFileInputsManifestInvalidError,
    DoFilePlanInvalidError,
    DoFileTemplateUnsupportedError,
)

logger = logging.getLogger(__name__)

DEFAULT_SUMMARY_TABLE_FILENAME = "ss_summary_table.csv"


@dataclass(frozen=True)
class ExpectedOutput:
    kind: ArtifactKind
    filename: str


@dataclass(frozen=True)
class GeneratedDoFile:
    do_file: str
    expected_outputs: tuple[ExpectedOutput, ...]


def _stata_quote(value: str) -> str:
    escaped = value.replace('"', '""')
    return f'"{escaped}"'


def _extract_generate_step(plan: LLMPlan) -> PlanStep:
    for step in plan.steps:
        if step.type == PlanStepType.GENERATE_STATA_DO:
            return step
    raise DoFilePlanInvalidError(reason="missing_generate_step")


def _extract_template(step: PlanStep) -> str:
    template = step.params.get("template", "")
    if not isinstance(template, str) or template.strip() == "":
        raise DoFilePlanInvalidError(reason="missing_template")
    return template


def _extract_primary_dataset_rel_path(inputs_manifest: Mapping[str, object]) -> str:
    dataset = inputs_manifest.get("primary_dataset")
    rel_path: object
    if isinstance(dataset, Mapping):
        rel_path = dataset.get("rel_path", "")
    else:
        rel_path = inputs_manifest.get("primary_dataset_rel_path", "")

    if not isinstance(rel_path, str):
        raise DoFileInputsManifestInvalidError(reason="primary_dataset_rel_path_not_string")
    if rel_path.strip() == "":
        raise DoFileInputsManifestInvalidError(reason="primary_dataset_rel_path_missing")
    if not is_safe_job_rel_path(rel_path):
        raise DoFileInputsManifestInvalidError(reason="primary_dataset_rel_path_unsafe")
    return rel_path


def _render_stub_descriptive_v1(*, plan_id: str, dataset_job_rel_path: str) -> str:
    dataset_from_work_dir = f"../../{dataset_job_rel_path}"
    lines = [
        "version 17",
        "clear all",
        "set more off",
        "",
        "* Generated by SS DoFileGenerator (deterministic).",
        f"* plan_id: {plan_id}",
        "* template: stub_descriptive_v1",
        "",
        f"use {_stata_quote(dataset_from_work_dir)}, clear",
        "",
        "quietly describe",
        "local ss_k = r(k)",
        "quietly summarize",
        "local ss_N = r(N)",
        "",
        "clear",
        "set obs 2",
        'generate str16 metric = ""',
        "generate double value = .",
        'replace metric = "N" in 1',
        "replace value = `ss_N' in 1",
        'replace metric = "k" in 2',
        "replace value = `ss_k' in 2",
        f"export delimited using {_stata_quote(DEFAULT_SUMMARY_TABLE_FILENAME)}, replace",
        "",
        "exit, clear",
        "",
    ]
    return "\n".join(lines)


class DoFileGenerator:
    def generate(self, *, plan: LLMPlan, inputs_manifest: Mapping[str, object]) -> GeneratedDoFile:
        logger.info("SS_DOFILE_GENERATE_START", extra={"plan_id": plan.plan_id})
        step = _extract_generate_step(plan)
        template = _extract_template(step)
        dataset_rel_path = _extract_primary_dataset_rel_path(inputs_manifest)

        if template != "stub_descriptive_v1":
            raise DoFileTemplateUnsupportedError(template=template)

        do_file = _render_stub_descriptive_v1(
            plan_id=plan.plan_id,
            dataset_job_rel_path=dataset_rel_path,
        )
        outputs = (
            ExpectedOutput(
                kind=ArtifactKind.STATA_EXPORT_TABLE,
                filename=DEFAULT_SUMMARY_TABLE_FILENAME,
            ),
        )
        logger.info(
            "SS_DOFILE_GENERATE_DONE",
            extra={"plan_id": plan.plan_id, "template": template, "outputs": len(outputs)},
        )
        return GeneratedDoFile(do_file=do_file, expected_outputs=outputs)
